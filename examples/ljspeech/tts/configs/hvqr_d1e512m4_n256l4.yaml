id: "hvqr_d1e512m4_n256l4"

#################################################
# Task configuration
#################################################

task:
    _name: "Autoencoder"
    network:
        autoencoder:
            _name: "HVQR"
            in_dim: 80
            n_model_size: 256
            downsample_scales: [1]
            embedding_sizes: [512]
            n_heads: 4
            transformer_config:
                max_seq_len: 2400
                n_layers: 4
                n_head: 2
                d_k: 64
                d_v: 64
                d_model: 256
                d_inner: 1024
                fft_conv1d_kernel: 3
                fft_conv1d_padding: 1
                dropout: 0.1
                fused_layernorm: False
            vocoder_config:
                upsample_rates: [5, 5, 4, 3]
                upsample_kernel_sizes: [11, 11, 8, 7]
                upsample_initial_channel: 512
                resblock_kernel_sizes: [3, 7, 11]
                resblock_dilation_sizes: [[1, 3, 5], [1, 3, 5], [1, 3, 5]]
                num_mels: 256
        discriminator:
            _name: 'HifiGANDiscriminator'


#################################################
# Trainer configuration
#################################################

# Basic hyperparameters
save_checkpoint_dir: "egs/ljspeech/tts/checkpoints/hvqr_d1e512m4_n256l4"
pretrain_checkpoint_path: ""
restore_checkpoint_path: ""
resume_training: True
training_steps: 800000
iters_per_checkpoint: 10000
seed: 1234

# CuDNN configuration
cudnn:
    enabled: True
    benchmark: True

# Specific trainer hyperparameters
trainer:
    _name: 'HVQRTrainer'
    lambda_vq: 1
    sample_lengths: 21000
    stft_loss_supervised_step: 50000
    lambda_fm: 2
    lambda_mel: 45

optimizer:
    _default:
        _name: "AdamW"
        learning_rate: 2e-4
        betas: [0.8, 0.99]
        eps: 1e-8
        weight_decay: 0.0
    
dataloader:
    batch_size: 16
    num_workers: 4

dataset:
    _name: 'MelDataset'
    id_list: "/data/hhguo/corpus/ljspeech/train_tts.list"
    samplerate: 24000
    feature: ['mel', 'wav']
    feature_path: [
        '/data/hhguo/corpus/ljspeech/mel/{}.npy',
        '/data/hhguo/corpus/ljspeech/wav_24k/{}.wav',
    ]
    dimension: [80, 1]
    frameshift: [300, 1]
    padding_value: [-4, 0]
    pre_load: False
    segment_length: 96000 # samples

lr_scheduler:
    _name: "ExponentialDecayLRScheduler"
    warmup_steps: 200000
    decay_learning_rate: 0.5
    final_learning_rate: 1e-5

# Only for Multi-GPU Training
distributed:
    dist_backend: "nccl"
    dist_url: "tcp://localhost:54321"

#################################################
# Infer configuration
#################################################

save_features: [['wav', '.wav', 24000]]